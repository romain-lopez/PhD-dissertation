In this thesis, we have covered multiple aspects around the utilisation of DGMs for single-cell transcriptomics. In this section, we selected a subset of problems and avenues related, although not thourougly covered by the previous chapters. 


\section{Model selection}
With the recent proliferation of DGMs, more consideration needs to be given to \textit{model selection}: the task of comparing the performance of two or more candidate models. % or of different parametrizations of the same model. %This occurs at design time or later on during benchmarking, while selecting among the possible variants of a single model.
Aspects of model selection that may be of interest can include different choices for the family of distributions we use in the model (as in scVAE~\cite{Gronbech2019}) or to the hyperparameters (e.g., neural networks architecture or parameters of the optimization procedure; refer to~\cite{Eraslan2019} for further details about hyperparameters). In all of these scenarios, the methodology developed for \textit{model criticism} applies and should be used whenever appropriate. The starting point is the assessment of the goodness of fit, often done via estimation of the likelihood of held out data and posterior predictive checks in the case of VAEs. However, recent work showed that held-out log-likelihood might not be correlated with performance for certain downstream analyses where biological plausibility is evaluated~\cite{Hu2019} (phenomenon also discussed in the machine learning literature~\cite{Theis2016}). %This might be due to the fact that it can be hard to design a model perfectly suitable for a wide range of tasks. 
Consequently, improvements on goodness of fit may not be convincing enough and generative models must therefore be evaluated, whenever possible, in the context of their prospective use. A notable example of evaluation framework is TAPE~\cite{Rao2019}, which provides public data sets, evaluation metrics and non-trivial training-test-validation splits for assessing algorithms for embedding protein sequences. Such an effort in applications ranging from machine learning to molecular biology will allow fast, reproducible and scientifically relevant methodology developments. 


\section{Generation of out-of-sample data}

The ability to generate data can also be used for extending beyond our observations -- namely generating and then drawing conclusions from new data points that are fundamentally different from the observed ones. This can be done by sampling from areas of the latent space to which none of the observed data points is mapped, but that may still have a meaning. A popular way to do that is using the so-called latent space arithmetic, namely performing linear operations on the latent representation of observed points and generating data from the resulting coordinates. For instance, one may sample points in latent space along a line between two observed data points, presumably spanning all intermediate states between these points. While latent space arithmetic does not have any theoretical guarantees, it has been successfully applied in computer vision, for instance to linearly interpolate between $z_0$, the latent representation of an image of faces looking left and $z_1$, of a face looking right, thus generating an artificial, yet smooth left-to-right transition~$x_t$~\cite{Radford2016}. 
\begin{align}
\begin{split}
    z_t &= tz_0 + (1-t)z_1 \\
    x_t &= \mathbb{E}_{p(x \mid z_t)}[x]
\end{split}
\end{align}
An application of this idea in molecular biology was presented by Ghahramani and colleagues \cite{Ghahramani2018} who used latent space arithmetic to simulate epidermal differentiation. Here a GAN was trained on scRNA-seq data sets of epidermal cells and a differentiation gradient was estimated in the latent space by subtracting the latent representations of differentiated and undifferentiated cells. This gradient was then used to study epidermal cell differentiation in silico. Notably, mapping an observation $x$ (here a cell's transcriptome) back to its latent representation $z$ is not trivial with GAN since, unlike VAES, they do not include a posterior distribution $p(z \mid x)$. 

To resolve this, the authors proposed to randomly sample points from the latent space (i.e., inputs to the generator network $G)$ until a point $z'$ is found whose generated transcriptome $G(z')$ is sufficiently similar to the desired $x$.


By starting from the latent representation of a specific undifferentiated cell and following the differentiation gradient, new and unobserved points were then sampled at various points along the undifferentiated - undifferentiated segment. These points in latent space were then converted to a full dimensional points (in gene expression space) using the GAN generator. The authors use these simulated profiles to understand the dynamics of the differentiation process, and verified that known differentiation markers such as Ppl and Grhl3 increase over the simulated process. 


Latent space arithmetic is also central to the method scGen \cite{Lotfollahi2018}, which uses a VAE framework to predict the effect of any given perturbation (e.g., chemical treatments) on the trascritomes cells. First, the authors derive a perturbation vector that represents the difference in latent space between the average transcriptomes of perturbed $x_p$ and unperturbed $x_u$ cells. Applying this vector to the latent representation $x^*_u$ of cells of a different type for which perturbation data is not available, results in the generation of perturbed expression profiles $\tilde{x}_p$, using the formula
\begin{align}
\begin{split}
    \delta &= \mathbb{E}_{q(z_p \mid x_p)}[z_p] - \mathbb{E}_{q(z_u \mid x_u)}[z_u]\\
    \tilde{z}_p &=  \mathbb{E}_{q(z_u \mid x^*_u)}[z_u] + \delta \\
    \tilde{x}_p &= \mathbb{E}_{p(x_p \mid \tilde{z}_p)}[x_p]
\end{split}
\end{align}
This generated expression profile is then validated using held-out data. The authors also showed that this method can be used to correct batch effects (estimated by a gradient representing the latent space difference between batches). We stress that these methods do not come with theoretical guarantees and that conclusions drawn from out-of-sample generation require manual inspection. Indeed, DGMs often fail to capture the full extent of the semantics contained in the dataset. For example, a dataset of shape drawings is used to train a DGM in~\cite{Zhao2018}. While each image of the training set contains exactly six colored dots, the images generated from the DGM can contain a variable number of dots. This shows that the model learned only a limited semantic and in a biological setting could generate artifacts that are irrelevant to scientists. This risk can be mitigated by careful assumptions as well as experimental validation. 


\section{Interpretability of deep generative models}

Generally, it is difficult to interpret internal hidden neurons of the neural networks of a deep generative model. Still, there are several examples where manual examination or algorithmic procedures can unravel interesting information. Some of the topics we refer to here may be related to the field of explainable machine learning~\cite{gilpin2018explaining}.

First, it is known that linearity is an efficient way to get interpretability (as in principal component analysis). Therefore, it is quite natural to investigate the last layer of the neural network (which is followed by the output layer) since these neurons are often linked to the output with a linear function. This last linear transformation can be used to discover feature-specific information either in generative networks of VAEs or generators of GANs. In~\cite{Ghahramani2018}, a GAN is trained on scRNA-seq data and a gene-gene covariance matrix is constructed through representing each gene by the weights of the final neural network layer. While this approach is interesting, we note that it comes with no theoretical guarantees and may produce spurious correlations. In~\cite{Svensson737601}, a VAE with a linear decoder (LDVAE) is proposed for scRNA-seq data. The LDVAE trades model fit for more interpretability since the decoder now relates directly latent variables to the expression of individual genes. 

For some type of data, features can have a spatio-temporal structure such as pixels in images, sampling of a time-series or sequence data. In this case a common practice is to structure the architecture in a way that each hidden variable can focus on only a certain region (e.g., area of the image) at a time. These so-called attention mechanisms~\cite{bahdanau2015} may be an attractive solution for interpreting predictions of a neural network. In~\cite{manica2019}, the multi-modal convolutional neural networks have an attention mechanism to encode the SMILES string of the chemical compounds as well as gene expression and predict drug sensitivity. Their results suggest that the attention mechanism focuses on relevant genes and functional groups for understanding progression of leukemia. While attention mechanisms have proven to be successful in areas of natural language processing~\cite{bahdanau2015}, applications to biology should control at least a measure of risk such as the false discovery rate. Current approaches have no methods for providing such guarantees. 

In a certain number of real-world instances, using a linear model might result in an important loss of performance and the input data might not have spatial structure such as molecular information. In that setting, the Shapley value (the expected marginal contribution over all possible subsets) can be a valuable tool to assess feature importance and interpret models. Although the original Shapley value is computationally intensive, recent research work provided tractable approximations~\cite{NIPS2017_7062} to interpret complex models and large data sets. Such approach have been applied to explainable predictions of anti-cancer drug synergy~\cite{janizek2018explainable}. In this work, Janizek et al. provide a model which outperforms state-of-the-art predictions and provides biological insight into relevant pathways for understanding drug synergy in leukemia treatment. More systematic use of such tools may be an important direction to take for applications of machine learning in computational biology.

A more Bayesian procedure for interpretability is to treat the weights of the neural networks as hidden random variables with a sparsity inducing prior (e.g., a Laplacian, Gamma or a spike and slab prior depending on the property of interest), as in DeepSequence. Similarly, the concrete autoencoder~\cite{balin2019concrete} performs combinatorial optimization to find the optimal subset of features which better recapitulates the input data. This latter technique could be applied more widely to investigate feature importance for different hidden random variables for example. 

\section{Utilizing uncertainty for Bayesian decision-making}
The Bayesian model in Equation~\eqref{factorization} provides a joint probability distribution $p_\theta(x, y)$ that, along with Bayes rule, fully describes the latent variables associated with each data point (i.e., the posterior distribution $p_\theta(z\mid x)$). Variational methods provide an approximation to this posterior  (i.e., $q_\phi(z\mid x)$) and therefore, as soon as the quality of the approximation is sufficient, one can obtain a myriad of uncertainty measures about our observations, such as a credible interval (or region) around the observed value $x$. Estimating and utilizing this uncertainty is an area of much attention in the machine learning literature, especially in the context of active learning and reinforcement learning~\cite{Osband2018RandomizedLearning}. More generally, the posterior can be used for any type of Bayesian decision-making procedure such as hypothesis testing, issuing natural hazard warnings in public policy~\cite{economou2016use} and novelty detection in robotics~\cite{amini2018variational}. In this section, we present work that makes implicit appeal to Bayesian decision theory~\cite{berger2013statistical} in order to ground scientific discoveries. 

One natural utilization of the approximate posterior is to approximate the marginal log-likelihood of each data point, which can help highlight observations that are not described well by the model. In the context of scRNA-seq, this concept was used by scvis~\cite{Ding2018} to identify novel sub-populations of cells. Specifically, the authors first trained a VAE on a set of mouse retinal bipolar cells. Then, another data set of cells from the entire retina was embedded in the same latent space, without re-fitting the model. The authors found that non-bipolar cells from the full retina data set had lower likelihood than bipolar cells. While this trend was expected given our a-priori knowledge on the assayed cells, it served to validate this use of VAEs as a general way of identifying sub populations of cells that are present in a new sample and were not in any previous ones. %These results suggests that VAEs such as scvis can have a proper notion of confidence about whether some data points are sampled from the source distribution (e.g., here the bipolar cells) or not. 


One useful application of the approximate posterior is to estimate the marginal likelihood of each data point. For example, scvis~\cite{Ding2018} utilized this marginal likelihood to assess the model fit of each cell in a scRNA-seq data. The authors of scvis explored the scenario of training a VAE with one scRNA-seq sample and then projecting a new sample onto the same embedding (namely, for every cell $i$, evaluate $q_\phi(z_i \mid x_i)$ without re-fitting the model's parameters $\phi$). By estimating the marginal likelihood of the already- trained model for each cell from the new data set, this analysis provides a way of estimating which parts of the new data set can be confidently used and also highlights cell populations that were only observed in the new sample. This application is useful in practical settings where one invests a great deal of effort in studying and interpreting the embedding of one set of samples, and may save the need to revise this work when new samples arrive. 


A more complex application of uncertainty in molecular biology is for decision making via likelihood-ratios. In the case of scVI, the posterior distribution over the latent space can be used to derive credible intervals of gene expression levels (reflecting measurement uncertainty), thus enabling estimation of differential expression. Indeed, differential expression can be formulated as a Bayesian decision making problem (whether the expression of a gene is significantly changing between two populations of cells). Building on this idea, scVI uses a likelihood ratio (comparing the two models of either ``differential'' or ``no difference'' in gene expression), approximated by sampling from the posterior distribution $q_\phi(z \mid x)$ and then the generative model $p_\theta(x\mid z)$, of cells in the two populations of interest. 

Estimation of uncertainty can be used for other critical tasks in scRNA-seq analysis, beyond differential expression. One example is assignment of cell type labels, which is often done by drawing arbitrary cutoffs between clusters (i.e., with no regards to uncertainty). One way to address this was implemented in scANVI~\cite{Xu2019} where cell type annotations $c$ are treated in a semi-supervised learning fashion (e.g., only labels with high confidence such as from cells expressing key marker genes from a curated gene set).  The model learns a likelihood distribution $p(x\mid z,c)$ that conditions the gene expression values $x$ not only on the latent space $z$ but also on the annotation $c$. This model treats cell types $c$ as a random variable and defines a posterior $p(c \mid x)$ that can then be estimated with variational inference~\cite{kingma2014semi}. This enables us to provide prediction as well as uncertainty for cell types based on the variational posterior $q_\phi(c \mid x)$. Results suggest that this uncertainty can also be useful for differential expression, since we longer compare two fixed sets of cells (which might include misannotated cells), but rather draw from the posterior of these sets. 

Another application of uncertainty to decision making is the prediction of effects of mutations in DeepSequence~\cite{DeepSequence}. In this work, the main assumption is that the training data is enriched for biological sequences (e.g., proteins) that were selected during evolution and are therefore likely functional. In this setting, the model is assumed to attribute high marginal likelihood to sequences that represent functional proteins (possibly harboring non-deleterious mutations) and low marginal likelihood to sequences that include deleterious mutations (which were presumably under-represented in the training set). Interestingly, the likelihood ratio wild type $p_\theta(x_{\textrm{wt}})$ to mutation $p_\theta(x_{\textrm{m}})$ is informative of how much evidence there is that mutation $x_{\textrm{m}}$ is functional or deleterious. 
\begin{align}
    \log \frac{p_\theta(x_{\textrm{wt}})}{p_\theta(x_{\textrm{m}})}
\end{align}

These preliminary applications of decision-theory to real biological problems are promising and can potentially be applied to more critical problems such as online exploration of treatments or even experimental design. However, these will probably require further developments of the inference mechanisms. Indeed, correctly estimating log-likelihood ratios or marginal log-likelihood requires to have at disposal a variational distribution close to the model's posterior. In practice, variational inference does not provide a provably efficient approximation method and in certain instances, estimations of log-likelihood ratios can be especially inaccurate. Recent developments in variational inference provide empirical procedures to assess the quality of the approximate posterior distribution~\cite{yao2018yes}, as well as alternative training procedures that yield more suitable posterior distributions~\cite{le2018revisiting,sbVAE}. We expect that these tools will play an important role in building meaningful and principled applications of VAEs to molecular biology.



\section{Beyond statistical associations and towards causal inference}
\label{box:causal}
Causal inference~\cite{pearl2009causality} provides a principled way of reasoning about actions and outcomes. While generally, causal inference is out of the scope for this review, we will briefly discuss how this paradigm, combined with DGMs might be applied to questions in molecular biology.

A key class of problems in causal inference relates to counterfactuals. This is an especially common topic in healthcare, where key questions are of the form ``what would have been the treatment leading to the optimal outcome for this particular patient?''. Notably, deep generative models have been used to study causal effects~\cite{pearl2009causality} on semi-simulated data, for marketing or healthcare applications (e.g., individualized treatment effect estimation~\cite{Louizos2017, yoon2018ganite, lopez.cost}). However, accurately recovering treatment effect from observational (rather than interventional) data requires first that there are no hidden confounders that control treatment outcome and second that it was feasible to assign to each observed case actions different from the one observed. 

Classically, integration of single-cell transcriptomics data is a very critical field of research but which does not satisfy the hypothesis mentioned above. For example, let us consider a clinical study performed via scRNA-seq and in which there are $n$ patients for control and $n$ others for the phenotype of interest. scRNA-seq is performed via the same protocol but on different days. Of course, there are probably some hidden confounders such as age, sex or lineage but more importantly each cell is assigned almost surely to the same batch (since scRNA-seq is a destructive method). Consequently, having a general understanding of how individual cells react to phenotypical changes is in general intractable and one might resort to more structured hypotheses. For example, scGen~\cite{Lotfollahi2018} assumes that in its latent space all cell types between conditions are affected by the same vector translation. While this might be a reasonable assumption in the particular case studied in the manuscript, such an hypothesis may not hold in a more general setting of cell type specific response to a stimulation. In particular, such an approach might yield spurious discoveries and a more suitable approach would be to re-think some experiments design. Indeed, another workaround to identify causal effects is to be able to perform interventions (e.g., force key variables to have some fixed values). A particularly promising framework is Pertub-seq~\cite{Dixit2016}, for which CRISPR perturbations (e.g., interventions) allow to estimate causal effect for transcription factors or gene modules.   
