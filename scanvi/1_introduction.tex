\section{Introduction}
Recent technological improvements in microfluidics and low volume sample handling~\cite{tanay2017scaling} have enabled the emergence of single-cell transcriptomics~\cite{dropseq, zheng2017massively} as a popular tool for analyzing biological systems~\cite{Semrau2017, Gaublomme2015, Patel2014}. This growing popularity along with a continued increase in the scale of the respective assays~\cite{angerer} has resulted in massive amounts of publicly available data and motivated large scale community efforts such as the Human Cell Atlas~\cite{HCA}, Tabula Muris~\cite{quake2018single} and the BRAIN Initiative Cell Census Network~\cite{biccn}. The next natural step in the evolution of this field is therefore to integrate many available datasets from related tissues or disease models in order to increase statistical robustness~\cite{boost}, achieve consistency and reproducibility among studies~\cite{MNN,seurat}, and ultimately converge to a common ontology of cell states and types~\cite{HCA, wagner2016revealing}. 

A fundamental step toward the ideal of a common ontology is data \textit{harmonization}, namely integration of two or more transcriptomics datasets into a single dataset on which any downstream analysis can be applied. We use the term harmonization rather than \textit{batch effect correction} in order to emphasize that the input datasets may come from very different sources (\textit{e.g.}, technology, laboratory), and from samples with a different composition of cell types. A wide range of methods have already been developed for this fundamental problem, initially for microarrays and later on for bulk RNA sequencing, such as ComBat~\cite{combat} and limma~\cite{limma}. These approaches mainly rely on generalized linear models, with empirical Bayes shrinkage to avoid over-correction. More recently, similar methods have been proposed specifically for single-cell RNA sequencing (scRNA-seq), such as ZINB-WaVE~\cite{zinbwave}, which explicitly accounts for the overabundance of zero entries in the data. However, because of their linear assumptions, these approaches may not be appropriate when provided with a heterogeneous sample that includes different cell states, each of which may be associated with a different sample-to-sample bias~\cite{MNN}. With these limitations in mind, the next generation of methods turned to non-linear strategies. Broadly speaking, each of these methods includes a combination of two components: (i) joint factorization of the input matrices (each corresponding to a different dataset) to learn a joint low-dimensional latent representation. This is usually done with well established numerical methods, such as integrative non-negative matrix factorization (LIGER~\cite{LIGER}), singular value decomposition (Scanorama~\cite{scanorama}), or canonical correlation analysis (Seurat Alignment~\cite{seurat}); (ii) additional non-linear transformation of the resulting latent representations so as to optimally ``align'' them onto each other. This is usually done using heuristics, such as alignment of mutual nearest neighbors (MNN~\cite{MNN}, Scanorama~\cite{scanorama} and Seurat Anchors~\cite{SEURAT3}), dynamic time warping (Seurat Alignment~\cite{seurat}) or quantile normalization (LIGER~\cite{LIGER}). While this family of methods has been shown to effectively overlay different datasets, it suffers from two important limitations. First, an explicit alignment procedure may be difficult to tune in a principled manner and consequently result in over-normalization. This is especially relevant when the cell type composition is different between datasets and when technical differences between samples are confounded with biological differences of interest. Second, the alignment is done in an ad hoc manner and lacks probabilistic interpretability. Consequently, the resulting harmonized dataset is of limited use and cannot be directly applied for probabilistic decision-making tasks, for example differential expression. 


Besides harmonization, another important and highly related problem is that of automated \textit{annotation} of cell state. In principle, there are two ways to approach this problem. The first is \textit{ab initio} labeling of cells based on marker genes or gene signatures \cite{seurat,VISION,fastproject}. While this approach is intuitive and straightforward, its performance may be affected in the plausible case where marker genes are absent due to limitations in sensitivity. The second approach is to ``transfer'' annotations between datasets. In the simplest scenario, we have access to one dataset where states have been annotated either \textit{ab initio}, or using additional experimental measurements (e.g., protein expression~\cite{zheng2017massively, stoeckius2017simultaneous} or lineage tracing~\cite{Weinreb467886}) and another, unannotated dataset from a similar condition or tissue. The goal is to use the labeled data to derive similar annotations for the second dataset, whenever applicable. This task is often complicated by factors such as differences in technology (e.g., using Smart-Seq2 data to annotate 10x Chromium data), partial overlap in cell type composition (i.e., not all labels should be transferred and not all unannotated cells should be assigned a label), complex organization of the labels (e.g., hierarchy of cell types and sub-types~\cite{Moana}, continuum along phenotypic or temporal gradients), partial labeling (i.e., only a subset of cells from the ``annotated'' dataset can be assigned a label confidently), and the need to handle multiple (more than $2$) datasets in a principled and scalable manner. One way to address the annotation problem with this approach is  learning a classifier~\cite{Moana, scmap} in order to predict a fixed stratification of cells. However, this approach might be sensitive to batch effects, which could render a classifier based on a reference dataset less generalizable to an unannotated dataset. Another, more flexible approach is to transfer annotations by first harmonizing the annotated and unannotated datasets, thus also gaining from the benefits of having a single dataset that can be subject to additional, joint, downstream analysis.

In this chapter, we propose a strategy to address several of the outstanding hurdles in both of the harmonization and annotation problems. We first demonstrate that single-cell Variational Inference (scVI)~\cite{scvi} a deep generative model we previously developed for probabilistic representation of scRNA-seq data --- performs well in both harmonization and harmonization-based annotation, going beyond its previously demonstrated capacity to correct batch effects. We then introduce single-cell ANnotation using Variational Inference (scANVI), a new method that extends scVI and provides a principled way to address the annotation problem probabilistically while leveraging any available label information. Because scANVI is able to model cells with or without label information, it belongs to the category of semi-supervised learning algorithms. This flexible framework of semi-supervised learning can be applied to two main variants of the annotation problem. In the first scenario, we are concerned with a single dataset in which only a subset of cells can be confidently labeled (e.g., based on expression of marker genes) and annotations should then be transferred to other cells, when applicable. In the second scenario, annotated datasets are harmonized with unannotated datasets and then used to assign labels to the unannotated cells.

The inference procedure for both of the scVI and scANVI models relies on neural networks, stochastic optimization and variational inference~\cite{aevb,VFAE} and scales to large numbers of cells and datasets. Furthermore, both methods provide a complete probabilistic representation of the data, which non-linearly controls not only for sample-to-sample bias but also for other technical factors of variation such as over-dispersion, library size discrepancies and zero-inflation. As such, each method provides a single probabilistic model that underlies the harmonized gene expression values (and the cell annotations, for scANVI), and can be used for any type of downstream hypotheses testing. We demonstrate the latter point through a differential expression analysis on harmonized data. Furthermore, through a comprehensive analysis of performance in various aspects of the harmonization and annotation problems and in various scenarios, we demonstrate that scVI and scANVI compare favorably to current state-of-the-art methods. scANVI is publicly available at \url{https://github.com/YosefLab/scvi-tools}. An implementation for all of the analysis performed in this chapter is available at
\url{https://doi.org/10.5281/zenodo.2529945}.




